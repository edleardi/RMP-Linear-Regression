{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edward Leardi\n",
    "\n",
    "# Metis Project #2\n",
    "\n",
    "# Using Linear Regression with Ratemyprofessors.com Data\n",
    "\n",
    "# Part #2: Beautiful Soup HTML Parsing\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://cdn1.theodysseyonline.com/files/2016/02/23/6359184783982034321887056811_RateMyProfessors-logo.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"http://cdn1.theodysseyonline.com/files/2016/02/23/6359184783982034321887056811_RateMyProfessors-logo.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "* Imports csv file generate by Selenium\n",
    "* Reads in urls like a dictionary (key=school, value=list of urls to professors at that school)\n",
    "* My data was split into two csv's, so have to run at minimum twice on each csv\n",
    "* When originally run, I would slice the csv and define variables like prof_urls_60, to run on the first 60 schools, then run th next 60 by slicing and creating prof_urls_120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prof_urls = {}\n",
    "\n",
    "# Run on both dictionaries\n",
    "csv_dictionary1 = '/data/my_dictionary_1090.csv'\n",
    "csv_dictionary2 = '/data/my_dictionary_2000.csv'\n",
    "\n",
    "with open(csv_dictionary1) as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        school_id = int(row[0])\n",
    "        prof_url = row[1]\n",
    "        if school_id not in prof_urls:\n",
    "            prof_urls[school_id] = [prof_url]\n",
    "        else:\n",
    "            prof_urls[school_id].append(prof_url)\n",
    "\n",
    "# To run in increments, use following format:\n",
    "prof_urls_60 = dict(list(prof_urls.items())[0:60])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_list_of_urls = []\n",
    "full_list_of_prof_lists = []\n",
    "prof_rating_header_list = [\"ID\",\n",
    "                           \"URL\",\n",
    "                           \"Full_Name\",\n",
    "                           \"School\",\n",
    "                           \"Num_of_Ratings\",\n",
    "                           \"Overall_Rating\",\n",
    "                           \"Take_Again\",\n",
    "                           \"Difficulty\",\n",
    "                           \"Hotness\",\n",
    "                           \"TOUGH_GRADER\",\n",
    "                           \"GIVES_GOOD_FEEDBACK\",\n",
    "                           \"RESPECTED\",\n",
    "                           \"GET_READY_TO_READ\",\n",
    "                           \"PARTICIPATION_MATTERS\",\n",
    "                           \"SKIP_CLASS_YOU_WONT_PASS\",\n",
    "                           \"LOTS_OF_HOMEWORK\",\n",
    "                           \"INSPIRATIONAL\",\n",
    "                           \"BEWARE_OF_POP_QUIZZES\",\n",
    "                           \"ACCESSIBLE_OUTSIDE_CLASS\",\n",
    "                           \"SO_MANY_PAPERS\",\n",
    "                           \"CLEAR_GRADING_CRITERIA\",\n",
    "                           \"HILARIOUS\",\n",
    "                           \"TEST_HEAVY\",\n",
    "                           \"GRADED_BY_FEW_THINGS\",\n",
    "                           \"AMAZING_LECTURES\",\n",
    "                           \"CARING\",\n",
    "                           \"EXTRA_CREDIT\",\n",
    "                           \"GROUP_PROJECTS\",\n",
    "                           \"LECTURE_HEAVY\"\n",
    "                          ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run only once\n",
    "full_list_of_prof_lists.append(prof_rating_header_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run only once\n",
    "csv_counter = 0\n",
    "running_len_of_full_list_of_urls = 0\n",
    "\n",
    "# If BS gets stuck, or running in increments, manually reset csv_counter & running_len_of_full_list_of_urls\n",
    "# csv_counter = stuck_count\n",
    "# running_len_of_full_list_of_urls = stuck_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv counter: 1140\n",
      "running len of full list of urls: 48512\n",
      "csv counter: 1160\n",
      "running len of full list of urls: 49371\n",
      "csv counter: 1180\n",
      "running len of full list of urls: 50171\n",
      "csv counter: 1200\n",
      "running len of full list of urls: 51098\n",
      "csv counter: 1220\n",
      "running len of full list of urls: 52070\n",
      "csv counter: 1240\n",
      "running len of full list of urls: 52853\n",
      "csv counter: 1260\n",
      "running len of full list of urls: 53665\n",
      "csv counter: 1280\n",
      "running len of full list of urls: 54380\n",
      "csv counter: 1300\n",
      "running len of full list of urls: 55356\n",
      "csv counter: 1320\n",
      "running len of full list of urls: 56522\n",
      "csv counter: 1340\n",
      "running len of full list of urls: 58021\n",
      "csv counter: 1360\n",
      "running len of full list of urls: 58879\n",
      "csv counter: 1380\n",
      "running len of full list of urls: 59722\n",
      "csv counter: 1400\n",
      "running len of full list of urls: 60838\n",
      "csv counter: 1420\n",
      "running len of full list of urls: 61696\n",
      "csv counter: 1440\n",
      "running len of full list of urls: 62439\n",
      "csv counter: 1460\n",
      "running len of full list of urls: 63866\n",
      "csv counter: 1480\n",
      "running len of full list of urls: 64852\n",
      "csv counter: 1500\n",
      "running len of full list of urls: 65463\n",
      "csv counter: 1520\n",
      "running len of full list of urls: 66091\n",
      "csv counter: 1540\n",
      "running len of full list of urls: 66592\n",
      "csv counter: 1560\n",
      "running len of full list of urls: 67315\n",
      "csv counter: 1580\n",
      "running len of full list of urls: 68246\n",
      "csv counter: 1600\n",
      "running len of full list of urls: 69104\n",
      "csv counter: 1620\n",
      "running len of full list of urls: 69689\n",
      "csv counter: 1640\n",
      "running len of full list of urls: 70432\n",
      "csv counter: 1660\n",
      "running len of full list of urls: 71424\n",
      "csv counter: 1680\n",
      "running len of full list of urls: 72260\n",
      "csv counter: 1700\n",
      "running len of full list of urls: 73185\n",
      "csv counter: 1720\n",
      "running len of full list of urls: 73879\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/Users/EdwardLeardi/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e1efcadc67dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprof_rating_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/EdwardLeardi/anaconda/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/EdwardLeardi/anaconda/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/EdwardLeardi/anaconda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    516\u001b[0m         }\n\u001b[1;32m    517\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/EdwardLeardi/anaconda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/EdwardLeardi/anaconda/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m                 )\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/EdwardLeardi/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/EdwardLeardi/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/EdwardLeardi/anaconda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/EdwardLeardi/anaconda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/EdwardLeardi/anaconda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/EdwardLeardi/anaconda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# prof_urls_list = either full list or slice (below is the sliced list from cell 4)\n",
    "prof_urls_list = prof_urls_60\n",
    "\n",
    "for schoolid in prof_urls_list:\n",
    "    csv_counter += 1\n",
    "    for prof_list_url in prof_urls_list[schoolid]:\n",
    "        if prof_list_url.find(\"ShowRatings\") != -1:\n",
    "            full_list_of_urls.append(prof_list_url)\n",
    "            \n",
    "            \n",
    "    if csv_counter % 20 == 0:          \n",
    "        \n",
    "        # Extract out ratings for each prof url using Beautiful Soup            \n",
    "        for idx, url in enumerate(full_list_of_urls):\n",
    "            time.sleep(.25)\n",
    "            prof_rating_list = []\n",
    "            response = requests.get(url)\n",
    "            page = response.text\n",
    "            soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "            prof_rating_list.append(idx + running_len_of_full_list_of_urls)\n",
    "            prof_rating_list.append(url)\n",
    "\n",
    "            # First name, last name extraction\n",
    "            try:\n",
    "                fname = soup.find_all(class_='pfname')[0].text.strip()\n",
    "                lname = soup.find_all(class_='plname')[0].text.strip()\n",
    "                prof_rating_list.append(fname + \" \" + lname)\n",
    "            except:\n",
    "                prof_rating_list.append(\"error\")\n",
    "\n",
    "            # School extraction\n",
    "            try:\n",
    "                school = soup.find_all(class_='school')[0].text.strip()\n",
    "                prof_rating_list.append(school)\n",
    "            except:\n",
    "                prof_rating_list.append(\"error\")\n",
    "\n",
    "            # Number of ratings extraction\n",
    "            try:\n",
    "                num_of_ratings_string = soup.find_all(class_='table-toggle rating-count active')[0].text.strip()\n",
    "                num_of_ratings = int(re.sub(\"[^0-9]\", \"\", num_of_ratings_string))\n",
    "                prof_rating_list.append(num_of_ratings)\n",
    "            except:\n",
    "                prof_rating_list.append(\"error\")\n",
    "                \n",
    "            # Overall rating extraction\n",
    "            try:\n",
    "                overall_rating = float(soup.find_all(class_='grade')[0].text.strip())\n",
    "                prof_rating_list.append(overall_rating)\n",
    "            except:\n",
    "                prof_rating_list.append(\"error\")\n",
    "\n",
    "            # Would take again extraction\n",
    "            try:\n",
    "                would_take_again = soup.find_all(class_='grade')[1].text.strip()\n",
    "                prof_rating_list.append(would_take_again)\n",
    "            except:\n",
    "                prof_rating_list.append(\"error\")\n",
    "\n",
    "            # Level of diff extraction\n",
    "            try:\n",
    "                lvl_of_diff = float(soup.find_all(class_='grade')[2].text.strip())\n",
    "                prof_rating_list.append(lvl_of_diff)\n",
    "            except:\n",
    "                prof_rating_list.append(\"error\")\n",
    "\n",
    "            # Hotness extraction\n",
    "            try:\n",
    "                hotness = 3\n",
    "                chili_status = soup.find_all('img')[1].prettify()\n",
    "                if chili_status.find(\"cold-chili\") != -1:\n",
    "                    hotness = 0\n",
    "                elif chili_status.find(\"new-hot-chili\") != -1:\n",
    "                    hotness = 1\n",
    "                else:\n",
    "                    hotness = np.nan\n",
    "                prof_rating_list.append(hotness)\n",
    "            except:\n",
    "                prof_rating_list.append(\"error\")\n",
    "\n",
    "            # All tags extraction\n",
    "            try:\n",
    "                tag_box = soup.find_all(class_='tag-box')[0]\n",
    "                TOUGH = GIVES = RESPECTED = GET = PARTICIPATION = SKIP = LOTS = INSPIRATIONAL = BEWARE = ACCESSIBLE = SO = CLEAR = HILARIOUS = TEST = GRADED = AMAZING = CARING = EXTRA = GROUP = LECTURE = 0\n",
    "                for x in tag_box.find_all(class_='tag-box-choosetags'):\n",
    "                    tags = x.text.strip()\n",
    "                    tags_split = tags.split()\n",
    "                    tags_first_word = tags_split[0].upper()\n",
    "                    tag_count = int(re.sub(\"[^0-9]\", \"\", tags))\n",
    "\n",
    "                    if tags_first_word == \"TOUGH\":\n",
    "                        TOUGH = tag_count\n",
    "                    elif tags_first_word == \"GIVES\":\n",
    "                        GIVES = tag_count\n",
    "                    elif tags_first_word == \"RESPECTED\":\n",
    "                        RESPECTED = tag_count\n",
    "                    elif tags_first_word == \"GET\":\n",
    "                        GET = tag_count\n",
    "                    elif tags_first_word == \"PARTICIPATION\":\n",
    "                        PARTICIPATION = tag_count\n",
    "                    elif tags_first_word == \"SKIP\":\n",
    "                        SKIP = tag_count\n",
    "                    elif tags_first_word == \"LOTS\":\n",
    "                        LOTS = tag_count\n",
    "                    elif tags_first_word == \"INSPIRATIONAL\":\n",
    "                        INSPIRATIONAL = tag_count\n",
    "                    elif tags_first_word == \"BEWARE\":\n",
    "                        BEWARE = tag_count\n",
    "                    elif tags_first_word == \"ACCESSIBLE\":\n",
    "                        ACCESSIBLE = tag_count\n",
    "                    elif tags_first_word == \"SO\":\n",
    "                        SO = tag_count\n",
    "                    elif tags_first_word == \"CLEAR\":\n",
    "                        CLEAR = tag_count\n",
    "                    elif tags_first_word == \"HILARIOUS\":\n",
    "                        HILARIOUS = tag_count\n",
    "                    elif tags_first_word == \"TEST\":\n",
    "                        TEST = tag_count\n",
    "                    elif tags_first_word == \"GRADED\":\n",
    "                        GRADED = tag_count\n",
    "                    elif tags_first_word == \"AMAZING\":\n",
    "                        AMAZING = tag_count\n",
    "                    elif tags_first_word == \"CARING\":\n",
    "                        CARING = tag_count\n",
    "                    elif tags_first_word == \"EXTRA\":\n",
    "                        EXTRA = tag_count\n",
    "                    elif tags_first_word == \"GROUP\":\n",
    "                        GROUP = tag_count\n",
    "                    elif tags_first_word == \"LECTURE\":\n",
    "                        LECTURE = tag_count\n",
    "\n",
    "                prof_rating_list.append(TOUGH)\n",
    "                prof_rating_list.append(GIVES)\n",
    "                prof_rating_list.append(RESPECTED)\n",
    "                prof_rating_list.append(GET)\n",
    "                prof_rating_list.append(PARTICIPATION)\n",
    "                prof_rating_list.append(SKIP)\n",
    "                prof_rating_list.append(LOTS)\n",
    "                prof_rating_list.append(INSPIRATIONAL)\n",
    "                prof_rating_list.append(BEWARE)\n",
    "                prof_rating_list.append(ACCESSIBLE)\n",
    "                prof_rating_list.append(SO)\n",
    "                prof_rating_list.append(CLEAR)\n",
    "                prof_rating_list.append(HILARIOUS)\n",
    "                prof_rating_list.append(TEST)\n",
    "                prof_rating_list.append(GRADED)\n",
    "                prof_rating_list.append(AMAZING)\n",
    "                prof_rating_list.append(CARING)\n",
    "                prof_rating_list.append(EXTRA)\n",
    "                prof_rating_list.append(GROUP)\n",
    "                prof_rating_list.append(LECTURE)\n",
    "            except:\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "                prof_rating_list.append(\"error\")\n",
    "\n",
    "            full_list_of_prof_lists.append(prof_rating_list)\n",
    "            \n",
    "        \n",
    "        running_len_of_full_list_of_urls += len(full_list_of_urls)\n",
    "        \n",
    "        output_csv_name = \"output\" + str(csv_counter) + \".csv\"\n",
    "        with open(output_csv_name, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(full_list_of_prof_lists)\n",
    "        full_list_of_urls = []\n",
    "        full_list_of_prof_lists = []\n",
    "        \n",
    "        print(\"csv counter: \" + str(csv_counter))\n",
    "        print(\"running len of full list of urls: \" + str(running_len_of_full_list_of_urls))\n",
    "\n",
    "\n",
    "        \n",
    "for i in range(5):\n",
    "    os.system(\"printf '\\a'\") # or '\\7'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020\n",
      "40775\n"
     ]
    }
   ],
   "source": [
    "# Run to check progress\n",
    "\n",
    "print(csv_counter)\n",
    "print(running_len_of_full_list_of_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
